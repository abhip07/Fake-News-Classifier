{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-02-14T16:16:49.886852Z","iopub.execute_input":"2022-02-14T16:16:49.887226Z","iopub.status.idle":"2022-02-14T16:16:49.905993Z","shell.execute_reply.started":"2022-02-14T16:16:49.887121Z","shell.execute_reply":"2022-02-14T16:16:49.904974Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"\n## Loading The Necessary Libraries","metadata":{}},{"cell_type":"code","source":"from tensorflow import keras\nfrom tensorflow.keras.layers import Embedding\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.preprocessing.text import one_hot\nfrom tensorflow.keras.layers import LSTM, Bidirectional\nfrom tensorflow.keras.layers import Dense\n\nimport nltk\nimport re\nfrom nltk.corpus import stopwords\nfrom nltk.stem.porter import PorterStemmer\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nimport warnings\n\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2022-02-14T16:16:49.908763Z","iopub.execute_input":"2022-02-14T16:16:49.909266Z","iopub.status.idle":"2022-02-14T16:16:52.756893Z","shell.execute_reply.started":"2022-02-14T16:16:49.909219Z","shell.execute_reply":"2022-02-14T16:16:52.755753Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"## Importing the Dataset","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv('../input/simplified-fake-news-dataset/train.csv')\ntest = pd.read_csv('../input/simplified-fake-news-dataset/test.csv')","metadata":{"execution":{"iopub.status.busy":"2022-02-14T16:16:52.758728Z","iopub.execute_input":"2022-02-14T16:16:52.759215Z","iopub.status.idle":"2022-02-14T16:16:54.239987Z","shell.execute_reply.started":"2022-02-14T16:16:52.759168Z","shell.execute_reply":"2022-02-14T16:16:54.238947Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"## Data Preprocessing","metadata":{}},{"cell_type":"code","source":"test.head()","metadata":{"execution":{"iopub.status.busy":"2022-02-14T16:16:54.241427Z","iopub.execute_input":"2022-02-14T16:16:54.241764Z","iopub.status.idle":"2022-02-14T16:16:54.259977Z","shell.execute_reply.started":"2022-02-14T16:16:54.241716Z","shell.execute_reply":"2022-02-14T16:16:54.259015Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"## Dropping Nan Values\n\ndataset = pd.concat([train, test], ignore_index=True)\n\n# Dropping null Values \ndataset = dataset.dropna()\n\n# Shuffeling the dataset along rows\ndataset = dataset.sample(frac=1)\nlabels = dataset['fake']\ndataset = dataset.drop('fake', axis=1)\n\ndataset.head()","metadata":{"execution":{"iopub.status.busy":"2022-02-14T16:16:54.261629Z","iopub.execute_input":"2022-02-14T16:16:54.261862Z","iopub.status.idle":"2022-02-14T16:16:54.324793Z","shell.execute_reply.started":"2022-02-14T16:16:54.261833Z","shell.execute_reply":"2022-02-14T16:16:54.323947Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"[dataset.shape, labels.shape]","metadata":{"execution":{"iopub.status.busy":"2022-02-14T16:16:54.326378Z","iopub.execute_input":"2022-02-14T16:16:54.327255Z","iopub.status.idle":"2022-02-14T16:16:54.333598Z","shell.execute_reply.started":"2022-02-14T16:16:54.327207Z","shell.execute_reply":"2022-02-14T16:16:54.332829Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"sns.set_style(style=\"darkgrid\")\nsns.countplot(x=labels)","metadata":{"execution":{"iopub.status.busy":"2022-02-14T16:16:54.335088Z","iopub.execute_input":"2022-02-14T16:16:54.335654Z","iopub.status.idle":"2022-02-14T16:16:54.533840Z","shell.execute_reply.started":"2022-02-14T16:16:54.335610Z","shell.execute_reply":"2022-02-14T16:16:54.532969Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"## Data Preprocessing","metadata":{}},{"cell_type":"code","source":"## Vocabulary size for one hot encoding\nvocab_size = 8000\n\n## Here we will only use title of news articles to train the model\nmessages = dataset.copy()\nmessages[\"title\"][0]","metadata":{"execution":{"iopub.status.busy":"2022-02-14T16:16:54.535538Z","iopub.execute_input":"2022-02-14T16:16:54.536062Z","iopub.status.idle":"2022-02-14T16:16:54.547969Z","shell.execute_reply.started":"2022-02-14T16:16:54.536018Z","shell.execute_reply":"2022-02-14T16:16:54.547326Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"messages.reset_index(inplace=True)\nmessages.head()","metadata":{"execution":{"iopub.status.busy":"2022-02-14T16:16:54.551337Z","iopub.execute_input":"2022-02-14T16:16:54.551711Z","iopub.status.idle":"2022-02-14T16:16:54.566685Z","shell.execute_reply.started":"2022-02-14T16:16:54.551669Z","shell.execute_reply":"2022-02-14T16:16:54.565863Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"### stopwords\nstopwords are words that are very common in human language but are generally not useful \nbecause they represent particularly common words such as “the”, “of”, and “to”.<br/>\nWe would not want these words to take up space in our database, or taking up valuable processing time. For this, we can remove them easily, by storing a list of words that you consider to stop words","metadata":{}},{"cell_type":"code","source":"stop_words = set(stopwords.words('english'))\n\nprint(stop_words, end=\" \")","metadata":{"execution":{"iopub.status.busy":"2022-02-14T16:16:54.568120Z","iopub.execute_input":"2022-02-14T16:16:54.568582Z","iopub.status.idle":"2022-02-14T16:16:54.575547Z","shell.execute_reply.started":"2022-02-14T16:16:54.568540Z","shell.execute_reply":"2022-02-14T16:16:54.574816Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"## Stemming and Tokenizing the titles","metadata":{}},{"cell_type":"code","source":"### Stemming The Dataset\nps = PorterStemmer()\ncorpus = []\nfor i in range(0, len(messages)):\n    review = re.sub('[^a-zA-Z]', ' ', messages['title'][i])\n    review = review.lower()\n    review = review.split()\n    \n    review = [ps.stem(word) for word in review if not word in stop_words]\n    review = ' '.join(review)\n    corpus.append(review)","metadata":{"execution":{"iopub.status.busy":"2022-02-14T16:16:54.577738Z","iopub.execute_input":"2022-02-14T16:16:54.578089Z","iopub.status.idle":"2022-02-14T16:17:03.509715Z","shell.execute_reply.started":"2022-02-14T16:16:54.578060Z","shell.execute_reply":"2022-02-14T16:17:03.508824Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"print(f\"Before Stemming: {messages.title[0]}\")\nprint(f\"After Stemming : {corpus[0]}\")\nlen(corpus)","metadata":{"execution":{"iopub.status.busy":"2022-02-14T16:17:03.511245Z","iopub.execute_input":"2022-02-14T16:17:03.511659Z","iopub.status.idle":"2022-02-14T16:17:03.518708Z","shell.execute_reply.started":"2022-02-14T16:17:03.511622Z","shell.execute_reply":"2022-02-14T16:17:03.517809Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"### One Hot Encoding\n#### This converts each word in corpus to index of their position in vocabulary","metadata":{}},{"cell_type":"code","source":"# Converting the messages to one hot encodings\nonehot = [one_hot(word, vocab_size) for word in corpus]\n\nfor i in range(5):\n    print(f\"Words : [{corpus[i]}]\")\n    print(f\"OneHot :{onehot[i]}\\n\")","metadata":{"execution":{"iopub.status.busy":"2022-02-14T16:17:03.520371Z","iopub.execute_input":"2022-02-14T16:17:03.520669Z","iopub.status.idle":"2022-02-14T16:17:04.248938Z","shell.execute_reply.started":"2022-02-14T16:17:03.520628Z","shell.execute_reply":"2022-02-14T16:17:04.248007Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"### Word Embedding \n- Word Embedding or Word Vector is a numeric vector input that represents a word in a lower-. dimensional space. It allows words with similar meaning to have a similar representation.<br/>\n- They try to preserve syntactical and semantic information>Word Embeddings are a method of extracting features out of text so that we can input those features into a machine learning model to work with text data.<br/>\n- They try to preserve syntactical and semantic information","metadata":{}},{"cell_type":"code","source":"## Padding the dataset so that each sentence will have same length\n\nmax_length=30\nembedded_docs=pad_sequences(onehot,padding='post',maxlen=max_length)\nprint(f\"After applying padding, the representation becomes : \\n\\n{embedded_docs[0]}\")","metadata":{"execution":{"iopub.status.busy":"2022-02-14T16:17:04.250757Z","iopub.execute_input":"2022-02-14T16:17:04.251059Z","iopub.status.idle":"2022-02-14T16:17:04.404761Z","shell.execute_reply.started":"2022-02-14T16:17:04.251019Z","shell.execute_reply":"2022-02-14T16:17:04.403766Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"## Creating the model","metadata":{}},{"cell_type":"code","source":"# length of an embedding vector for each word\nembedding_vector_length = 40\n\nmodel = Sequential(name=\"Fake_News_Detector\")\n\nmodel.add(Embedding(vocab_size, embedding_vector_length, input_length=max_length))\nmodel.add(keras.layers.BatchNormalization())\nmodel.add(keras.layers.Dropout(0.3))\nmodel.add((LSTM(128, return_sequences=True)))\nmodel.add(keras.layers.Dropout(0.2))\nmodel.add(Dense(64, activation='relu'))\nmodel.add(keras.layers.Dropout(0.3))\nmodel.add(Dense(1, activation='sigmoid', name=\"Output_Layer\"))\n\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-02-14T17:14:43.541212Z","iopub.execute_input":"2022-02-14T17:14:43.542176Z","iopub.status.idle":"2022-02-14T17:14:44.256979Z","shell.execute_reply.started":"2022-02-14T17:14:43.542117Z","shell.execute_reply":"2022-02-14T17:14:44.255995Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"markdown","source":"#### Compiling the Model","metadata":{}},{"cell_type":"code","source":"## Compiling the Model\nmodel.compile(\n    loss = keras.losses.BinaryCrossentropy(from_logits=True),\n    optimizer = 'adam',\n    metrics=['accuracy']\n)","metadata":{"execution":{"iopub.status.busy":"2022-02-14T17:14:53.507162Z","iopub.execute_input":"2022-02-14T17:14:53.507456Z","iopub.status.idle":"2022-02-14T17:14:53.517700Z","shell.execute_reply.started":"2022-02-14T17:14:53.507425Z","shell.execute_reply":"2022-02-14T17:14:53.516707Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"markdown","source":"## Training","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n## Final Dataset\n\nfinal_dataset = np.array(embedded_docs)\nfinal_labels = np.array(labels)\n\n## Splitting the dataset\nx_train, x_test, y_train, y_test = train_test_split(final_dataset, final_labels, test_size=0.33, random_state=0)\nfinal_labels[:5]","metadata":{"execution":{"iopub.status.busy":"2022-02-14T17:14:55.576020Z","iopub.execute_input":"2022-02-14T17:14:55.576330Z","iopub.status.idle":"2022-02-14T17:14:55.595737Z","shell.execute_reply.started":"2022-02-14T17:14:55.576293Z","shell.execute_reply":"2022-02-14T17:14:55.594861Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"\n## Training the model\nprint(\"\\n\\nTraining The Model\")\n\nTrain = model.fit(x_train, y_train, batch_size=64, validation_data=(x_test, y_test), epochs=10)","metadata":{"execution":{"iopub.status.busy":"2022-02-14T17:14:57.961214Z","iopub.execute_input":"2022-02-14T17:14:57.961753Z","iopub.status.idle":"2022-02-14T17:33:07.918805Z","shell.execute_reply.started":"2022-02-14T17:14:57.961710Z","shell.execute_reply":"2022-02-14T17:33:07.917828Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"markdown","source":"## Performance Metrics","metadata":{}},{"cell_type":"code","source":"## Evaluating the model on training set\n\nmodel.evaluate(x_test, y_test)","metadata":{"execution":{"iopub.status.busy":"2022-02-14T17:33:22.166706Z","iopub.execute_input":"2022-02-14T17:33:22.168046Z","iopub.status.idle":"2022-02-14T17:33:34.912586Z","shell.execute_reply.started":"2022-02-14T17:33:22.167996Z","shell.execute_reply":"2022-02-14T17:33:34.911720Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"## Making Predictions\ny_pred = (model.predict(x_test) > 0.5).astype(\"int32\")\ny_pred[50:60]","metadata":{"execution":{"iopub.status.busy":"2022-02-14T17:34:25.796775Z","iopub.execute_input":"2022-02-14T17:34:25.797546Z","iopub.status.idle":"2022-02-14T17:34:37.688880Z","shell.execute_reply.started":"2022-02-14T17:34:25.797494Z","shell.execute_reply":"2022-02-14T17:34:37.688265Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"# Confusion Matrix\n\nfrom sklearn.metrics import confusion_matrix\nprint(confusion_matrix(y_test, y_pred))","metadata":{"execution":{"iopub.status.busy":"2022-02-14T17:34:40.836809Z","iopub.execute_input":"2022-02-14T17:34:40.837113Z","iopub.status.idle":"2022-02-14T17:34:40.856086Z","shell.execute_reply.started":"2022-02-14T17:34:40.837081Z","shell.execute_reply":"2022-02-14T17:34:40.855068Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"# Classification report\n\nfrom sklearn.metrics import classification_report\nprint(classification_report(y_test, y_pred))","metadata":{"execution":{"iopub.status.busy":"2022-02-14T17:34:43.942003Z","iopub.execute_input":"2022-02-14T17:34:43.942534Z","iopub.status.idle":"2022-02-14T17:34:43.975920Z","shell.execute_reply.started":"2022-02-14T17:34:43.942491Z","shell.execute_reply":"2022-02-14T17:34:43.974910Z"},"trusted":true},"execution_count":55,"outputs":[]}]}